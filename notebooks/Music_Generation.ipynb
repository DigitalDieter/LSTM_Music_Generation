{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "#from keras.layers.recurrent import LSTM\n",
    "import keras.backend as K\n",
    "from IPython.display import Audio\n",
    "from pipes import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show libary versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# print python verion\n",
    "print(sys.version)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", k.__version__)\n",
    "print(\"Numpy:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav_as_np(file):\n",
    "    # wav.read returns the sampling rate per second  (as an int) and the data (as a numpy array)\n",
    "    data = wav.read(file)\n",
    "    # Normalize 16-bit input to [-1, 1] range\n",
    "    np_arr = data[1].astype('float32') / 32767.0\n",
    "    #np_arr = np.array(np_arr)\n",
    "    return np_arr, data[0]\n",
    "\n",
    "def write_np_as_wav(X, sample_rate, file):\n",
    "    # Converting the tensor back to it's original form\n",
    "    Xnew = X * 32767.0\n",
    "    Xnew = Xnew.astype('int16')\n",
    "    # wav.write constructs the .wav file using the specified sample_rate and tensor\n",
    "    wav.write(file, sample_rate, Xnew)\n",
    "    return\n",
    "\n",
    "def convert_sample_blocks_to_np_audio(blocks):\n",
    "    # Flattens the blocks into a single list\n",
    "    song_np = np.concatenate(blocks)\n",
    "    return song_np\n",
    "\n",
    "def convert_np_audio_to_sample_blocks(song_np, block_size):\n",
    "\n",
    "    # Block lists initialised\n",
    "    block_lists = []\n",
    "\n",
    "    # total_samples holds the size of the numpy array\n",
    "    total_samples = song_np.shape[0]\n",
    "    # print('total_samples=',total_samples)\n",
    "\n",
    "    # num_samples_so_far is used to loop through the numpy array\n",
    "    num_samples_so_far = 0\n",
    "\n",
    "    while (num_samples_so_far < total_samples):\n",
    "\n",
    "        # Stores each block in the \"block\" variable\n",
    "        block = song_np[num_samples_so_far:num_samples_so_far + block_size]\n",
    "\n",
    "        if (block.shape[0] < block_size):\n",
    "            # this is to add 0's in the last block if it not completely filled\n",
    "            padding = np.zeros((block_size - block.shape[0],))\n",
    "            # block_size is 44100 which is fixed throughout whereas block.shape[0] for the last block is <=44100\n",
    "            block = np.concatenate((block,padding))\n",
    "        block_lists.append(block)\n",
    "        num_samples_so_far += block_size\n",
    "    return block_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_blocks_to_fft_blocks(blocks_time_domain):\n",
    "    # FFT blocks initialized\n",
    "    fft_blocks = []\n",
    "    for block in blocks_time_domain:\n",
    "        # Computes the one-dimensional discrete Fourier Transform and returns the complex nD array\n",
    "        # i.e The truncated or zero-padded input, transformed from time domain to frequency domain.\n",
    "        fft_block = np.fft.fft(block)\n",
    "        # Joins a sequence of blocks along frequency axis.\n",
    "        new_block = np.concatenate((np.real(fft_block), np.imag(fft_block)))\n",
    "        fft_blocks.append(new_block)\n",
    "    return fft_blocks\n",
    "\n",
    "def fft_blocks_to_time_blocks(blocks_ft_domain):\n",
    "    # Time blocks initialized\n",
    "    time_blocks = []\n",
    "    for block in blocks_ft_domain:\n",
    "        # add type int\n",
    "        num_elems = int(block.shape[0] / 2)\n",
    "        # Extracts real part of the amplitude corresponding to the frequency\n",
    "        real_chunk = block[0:num_elems]\n",
    "        # Extracts imaginary part of the amplitude corresponding to the frequency\n",
    "        imag_chunk = block[num_elems:]\n",
    "        # Represents amplitude as a complex number corresponding to the frequency\n",
    "        new_block = real_chunk + 1.0j * imag_chunk\n",
    "        # Computes the one-dimensional discrete inverse Fourier Transform and returns the transformed\n",
    "        # block from frequency domain to time domain\n",
    "        time_block = np.fft.ifft(new_block)\n",
    "        # Joins a sequence of blocks along time axis.\n",
    "        time_blocks.append(time_block)\n",
    "    return time_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/training_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frequency = 44100\n",
    "block_size = 44100\n",
    "os.chdir(\"/Users/digitaldieter/coding/_github/LSTM_Music_Generation/datasets/training_data\")\n",
    "filename = 'Happy.mp3'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = filename.split('/')\n",
    "files\n",
    "orig_filename = files[-1][0:-4]\n",
    "if (filename[0] == '/'):\n",
    "    new_path = '/'\n",
    "for i in range(len(files) - 1):\n",
    "    new_path += files[i] + '/'\n",
    "# We define the file names for the newly created WAV files and the Mono mp3 file\n",
    "filename_tmp = new_path + orig_filename + 'Mono.mp3'\n",
    "new_name = new_path + orig_filename + '.wav'\n",
    "\n",
    "# These lines calls LAME to resample the audio file at the standard analog frequency of 44,100 Hz and then convert it to WAV\n",
    "sample_freq_str = \"{0:.1f}\".format(float(sample_frequency) / 1000.0)\n",
    "cmd = 'lame -a -m m {0} {1}'.format(quote(filename), quote(filename_tmp))\n",
    "os.system(cmd)\n",
    "cmd = 'lame --decode {0} {1} --resample {2}'.format(quote(filename_tmp), quote(new_name), sample_freq_str)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = new_path + orig_filename + 'Mono.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitrate, data = wav.read(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitrate, data = wav.read(new_name)\n",
    "# wav_array contains normalized data\n",
    "wav_array, bitrate = read_wav_as_np(new_name)\n",
    "# wav_array is converted into blocks with zeroes padded to fill the empty space in last block if any\n",
    "wav_blocks_zero_padded = convert_np_audio_to_sample_blocks(wav_array, block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattens the blocks into an array\n",
    "wav_array_zero_padded = convert_sample_blocks_to_np_audio(wav_blocks_zero_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_wav_blocks_zero_padded = wav_blocks_zero_padded[1:]\n",
    "shifted_wav_array_zero_padded = convert_sample_blocks_to_np_audio(shifted_wav_blocks_zero_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = time_blocks_to_fft_blocks(wav_blocks_zero_padded)\n",
    "Y = time_blocks_to_fft_blocks(shifted_wav_blocks_zero_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = np.concatenate(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_flat = np.concatenate(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_seq = 0\n",
    "chunks_X = []\n",
    "chunks_Y = []\n",
    "#max_seq_len = 10\n",
    "max_seq_len = 10\n",
    "total_seq = len(X)\n",
    "while cur_seq + max_seq_len < total_seq:\n",
    "    chunks_X.append(X[cur_seq:cur_seq + max_seq_len])\n",
    "    chunks_Y.append(Y[cur_seq:cur_seq + max_seq_len])\n",
    "    cur_seq += max_seq_len\n",
    "# Number of examples\n",
    "num_examples = len(chunks_X) \n",
    "# Imaginary part requires the extra space\n",
    "num_dims_out = block_size * 2\n",
    "# Dimensions of the training dataset\n",
    "out_shape = (num_examples, max_seq_len, num_dims_out)\n",
    "x_data = np.zeros(out_shape)\n",
    "y_data = np.zeros(out_shape)\n",
    "# Populating the training dataset\n",
    "for n in range(num_examples):\n",
    "    for i in range(max_seq_len):\n",
    "        x_data[n][i] = chunks_X[n][i]\n",
    "        y_data[n][i] = chunks_Y[n][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frequency_dimensions = (np.shape(X))[1]\n",
    "num_hidden_dimensions = 1024\n",
    "\n",
    "print('Input layer size: ',num_frequency_dimensions)\n",
    "print('Hidden layer size: ',num_hidden_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_dimensions = 1024\n",
    "num_frequency_dimensions = 88200\n",
    "num_recurrent_units = 1\n",
    "\n",
    "#l_activation='relu'\n",
    "l_activation='tanh'\n",
    "# other activator\n",
    "#l_activation='tanh'\n",
    "\n",
    "stateful = False\n",
    "\n",
    "model = Sequential()\n",
    "# This layer converts frequency space to hidden space\n",
    "model.add(TimeDistributed(Dense(num_hidden_dimensions, activation=l_activation),\n",
    "                          input_shape=(None, num_frequency_dimensions)))\n",
    "\n",
    "# model.add(TimeDistributedDense(input_dim=num_frequency_dimensions, output_dim=num_hidden_dimensions))\n",
    "for cur_unit in range(num_recurrent_units):\n",
    "    model.add(LSTM(num_hidden_dimensions, return_sequences=True, stateful=stateful))\n",
    "\n",
    "# This layer converts hidden space back to frequency space\n",
    "model.add(TimeDistributed(Dense(input_dim=num_hidden_dimensions, output_dim=num_frequency_dimensions,\n",
    "                                activation=l_activation)))\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "#print \"Compiling...\"\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "# Number of iterations for training\n",
    "num_iters = 20\n",
    "# Number of iterations before we save our model\n",
    "epochs_per_iter = 5\n",
    "# Number of training examples pushed to the GPU per batch.\n",
    "batch_size = 5\n",
    "\n",
    "# Path to weights file\n",
    "weights_path = 'weights/NP_Weights_Iter-' + str(num_iters)\n",
    "cur_iter = 0\n",
    "\n",
    "while cur_iter < num_iters:\n",
    "    \n",
    "    print('Iteration: ' + str(cur_iter))\n",
    "    # Iterate over the training data in batches\n",
    "    history = model.fit(x_data, y_data, batch_size=batch_size, epochs=epochs_per_iter, verbose=1, validation_split=0.0)\n",
    "    loss_list += history.history['loss'] \n",
    "    cur_iter += 1\n",
    "print('Training complete!')\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "p1 = plt.plot(range(len(history_list)),history_list)\n",
    "plt.title(weights_path)\n",
    "plt.savefig(str(weights_path) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the first chunk of the training data itself for seed sequence.\n",
    "seed_seq = x_data[0]\n",
    "# Reshaping the sequence to feed to the RNN.\n",
    "seed_seq = np.reshape(seed_seq, (1, seed_seq.shape[0], seed_seq.shape[1]))\n",
    "# Generated song sequence is stored in output.\n",
    "output = []\n",
    "for it in range(max_seq_len):\n",
    "    # Generates new value\n",
    "    seedSeqNew = model.predict(seed_seq) \n",
    "    # Appends it to the output\n",
    "    if it == 0:\n",
    "        for i in range(seedSeqNew.shape[1]):\n",
    "            output.append(seedSeqNew[0][i].copy())\n",
    "    else:\n",
    "        output.append(seedSeqNew[0][seedSeqNew.shape[1]-1].copy()) \n",
    "    # newSeq contains the generated sequence.\n",
    "    newSeq = seedSeqNew[0][seedSeqNew.shape[1]-1]\n",
    "    # Reshaping the new sequence for concatenation.\n",
    "    newSeq = np.reshape(newSeq, (1, 1, newSeq.shape[0]))\n",
    "    # Appending the new sequence to the old sequence.\n",
    "    seed_seq = np.concatenate((seed_seq, newSeq[:,1:,:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_song_nr = []\n",
    "gen_song_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path for the generated song\n",
    "gen_song_nr += 1\n",
    "song_path = 'generated_song_' +str(gen_song_nr) + \".wav\"\n",
    "# Reversing the conversions\n",
    "time_blocks = fft_blocks_to_time_blocks(output)\n",
    "song = convert_sample_blocks_to_np_audio(time_blocks)\n",
    "write_np_as_wav(song, sample_frequency, song_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bitrate, data = wav.read(song_path)\n",
    "plt.plot(data)\n",
    "plt.title(song_path)\n",
    "plt.xlabel(\"Time (x 10^(-5)s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "Audio(song_path)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
